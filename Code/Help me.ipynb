{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import bs4\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = ['Apple']\n",
    "years = ['2019', '2018']\n",
    "\n",
    "filing_type = '10-K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! We were able to find 1 of your queries in the S&P 500\n",
      "We found: ['Apple Inc.'] in the S&P 500\n",
      "{'Apple Inc.': ['AAPL', 320193]}\n"
     ]
    }
   ],
   "source": [
    "key_path = os.path.join('..','Financials', 'Ticker_and_CIK', 'Key.csv')\n",
    "\n",
    "key_df = pd.read_csv(key_path)\n",
    "\n",
    "key_dict = {}\n",
    "\n",
    "for query in range(len(company_list)):\n",
    "    try:\n",
    "        company_df = key_df[key_df['Company'].str.contains(company_list[query].title())]\n",
    "        key_dict[company_df.iloc[0, 1]] = [company_df.iloc[0, 0], company_df.iloc[0, 2]]\n",
    "    except IndexError:\n",
    "        print(f\"{company_list[query]} could not be found\")\n",
    "\n",
    "if key_dict == {}:\n",
    "    print (\"Whoops, none of your companies were on the S&P 500. Please try again!\")\n",
    "else:\n",
    "    print (f\"Success! We were able to find {len(key_dict.keys())} of your queries in the S&P 500\")\n",
    "    print (f\"We found: {list(key_dict.keys())} in the S&P 500\")\n",
    "    print (key_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AAPL': ['20180630', '20180331', '20171230', '20170701', '20170401', '20161231'], 'MMM': ['20180930', '20180630', '20180331', '20170930', '20170630', '20170331']}\n",
      "{'AAPL': ['2018-08-01', '2018-05-02', '2018-02-02', '2017-08-02', '2017-05-03', '2017-02-01'], 'MMM': ['2018-10-25', '2018-07-26', '2018-05-08', '2017-10-31', '2017-08-01', '2017-05-03']}\n"
     ]
    }
   ],
   "source": [
    "#Unmodified Base Code found at https://www.codeproject.com/Articles/1227765/Parsing-XBRL-with-Python\n",
    "#I added the ability for the code to query through a list of companies for multiple years and multiple quarters\n",
    "#and save the statements \n",
    "\n",
    "published_date_dict = {}\n",
    "as_of_date_dict = {}\n",
    "\n",
    "for companies_found in range(len(key_dict.keys())):\n",
    "    \n",
    "    company_name = list(key_dict.keys())[companies_found]\n",
    "    ticker = key_dict.get(company_name)[0]\n",
    "    \n",
    "    cik = key_dict.get(company_name)[1]\n",
    "    dateb = f'{years[0]}-12-31'\n",
    "    \n",
    "    # Obtain HTML for search page\n",
    "    base_url = \"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type={}&dateb={}\"\n",
    "    edgar_resp = requests.get(base_url.format(cik, filing_type, dateb))\n",
    "    edgar_str = edgar_resp.text\n",
    "    \n",
    "    doc_links = []\n",
    "    published_dates = []\n",
    "    as_of_dates = []\n",
    "            \n",
    "    # Find the document link\n",
    "    soup = BeautifulSoup(edgar_str, 'html.parser')\n",
    "    table_tag = soup.find('table', class_='tableFile2')\n",
    "    rows = table_tag.find_all('tr')\n",
    "        \n",
    "    for year in years:\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) > 3:\n",
    "                if year in cells[3].text:\n",
    "                    doc_link = 'https://www.sec.gov' + cells[1].a['href']\n",
    "                    published_date = cells[3].text\n",
    "                    published_dates.append(published_date)\n",
    "                    \n",
    "                    # Obtain HTML for document page\n",
    "                    doc_resp = requests.get(doc_link)\n",
    "                    doc_str = doc_resp.text\n",
    "                    # Find the XBRL link\n",
    "                    xbrl_link = ''\n",
    "                    soup_doc = BeautifulSoup(doc_str, 'html.parser')\n",
    "                    table_tag_doc = soup_doc.find('table', class_='tableFile', summary='Data Files')\n",
    "                    rows_doc = table_tag_doc.find_all('tr')\n",
    "                    for row_doc in rows_doc:\n",
    "                        cells_doc = row_doc.find_all('td')\n",
    "                        if len(cells_doc) > 3:\n",
    "                            if int(year) > 2018:\n",
    "                                if 'XML' in cells_doc[3].text:\n",
    "                                    xbrl_link = 'https://www.sec.gov' + cells_doc[2].a['href']\n",
    "                            else:\n",
    "                                if 'INS' in cells_doc[3].text:\n",
    "                                    xbrl_link = 'https://www.sec.gov' + cells_doc[2].a['href']\n",
    "                    # Obtain XBRL text from document\n",
    "                    xbrl_resp = requests.get(xbrl_link)\n",
    "                    xbrl_str = xbrl_resp.text\n",
    "               \n",
    "                    # Find and print stockholder's equity\n",
    "                    soup = BeautifulSoup(xbrl_str, 'lxml')\n",
    "                    tag_list = soup.find_all()\n",
    "                    \n",
    "                    df = pd.DataFrame()\n",
    "                    \n",
    "                    for tag in tag_list:\n",
    "                        if 'schemaref' in tag.name:\n",
    "                            ignored_href_index = len(ticker) + 1\n",
    "                            as_of_date = tag['xlink:href'][ignored_href_index:(ignored_href_index+8)]\n",
    "                            as_of_dates.append(as_of_date)\n",
    "                            \n",
    "                         #Modified from the original; The original searched through to find specific line items\n",
    "                        #Modified to search through every 10-Q per given year, and extract any financial line item into its own 10-Q\n",
    "\n",
    "                        if tag.name.find('us-gaap:') != -1:\n",
    "                            try: \n",
    "                                if float(tag.text) > 0:\n",
    "                                    i = [f'{tag.name}', tag.text, tag['contextref']]\n",
    "                                    i_series = pd.Series(i)\n",
    "                                    df = df.append(i_series, ignore_index = True)\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "\n",
    "                    folder_path = os.path.join('..','Financials',f'{filing_type}s',f'{ticker}')\n",
    "                    file_path = os.path.join('..','Financials',f'{filing_type}s',f'{ticker}', f'{ticker}_{published_date}.csv')\n",
    "\n",
    "                    try:\n",
    "                        os.mkdir(folder_path)\n",
    "                    except FileExistsError:\n",
    "                        pass\n",
    "                    df.to_csv(file_path, index = False)\n",
    "\n",
    "    published_date_dict[ticker] = published_dates\n",
    "    as_of_date_dict[ticker] = as_of_dates\n",
    "    \n",
    "print(as_of_date_dict)\n",
    "print(published_date_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0             1         2\n",
      "25  us-gaap:assetscurrent  1.068690e+11  FI2016Q4\n",
      "26  us-gaap:assetscurrent  1.033320e+11  FI2017Q1\n",
      "Series([], Name: 2, dtype: object)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = \"2017-02-01\"\n",
    "year = 2017\n",
    "\n",
    "#Get the saved 10-K     \n",
    "file_path = os.path.join('..','Financials',f'{filing_type}s',f'{ticker}', f'{ticker}_{date}.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "#Find the Current Ratio\n",
    "c_assets_df = df[df['0'].str.contains('us-gaap:assetscurrent')]\n",
    "print(c_assets_df)\n",
    "\n",
    "print(c_assets_df['2'][c_assets_df['2']==2017])\n",
    "\n",
    "reduced_df = c_assets_df[c_assets_df['2'].str.contains(f'{year}')]\n",
    "\n",
    "#if len(reduced_df ==)\n",
    "len(reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0             1         2\n",
      "26  us-gaap:assetscurrent  1.033320e+11  FI2017Q1\n"
     ]
    }
   ],
   "source": [
    "test_date = '20170201'\n",
    "\n",
    "y = test_date [0:4]\n",
    "m = test_date [4:6]\n",
    "d = test_date [6:8]\n",
    "year_check = int(y) + 1\n",
    "\n",
    "date_formats = [f'{y}{m}{d}', f'{y}-{m}-{d}', f'{m.lstrip(\"0\")}_{d.lstrip(\"0\")}_{y}']\n",
    "\n",
    "\n",
    "quarter_list = ['Q4', 'Q3', \"Q2\", \"Q1\"]\n",
    "\n",
    "context_ref = c_assets_df['2']\n",
    "\n",
    "\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "if len(context_ref) == 1:\n",
    "    test_df = test_df.append(c_assets_df)\n",
    "elif len(context_ref) == 0:\n",
    "    print('Error, There are no Entries for that')\n",
    "else:\n",
    "    while year_check >= (int(y)-1):\n",
    "        year_check_df = c_assets_df[context_ref.str.contains(f'{year_check}')]\n",
    "        \n",
    "        if len(year_check_df) == 1:\n",
    "            test_df = test_df.append(year_check_df)\n",
    "            break\n",
    "        else: \n",
    "            for item in date_formats:\n",
    "                if len(c_assets_df[context_ref.str.contains(f'{item}')]) == 1:\n",
    "                    test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{item}')])\n",
    "                    \n",
    "                    break\n",
    "            else:\n",
    "                for quarter in quarter_list:\n",
    "                    if len(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')]) == 1:\n",
    "                        test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')])\n",
    "                        \n",
    "                        break\n",
    "                    elif len(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')]) == 1:\n",
    "                        test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')])\n",
    "                        break\n",
    "        year_check = year_check - 1\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_ratio_dict = {}\n",
    "per_change_dict = {}\n",
    "bvps_dict = {}\n",
    "eps_dict = {}\n",
    "week_change_dict = {}\n",
    "month_change_dict = {}\n",
    "stock_price_dict = {}\n",
    "\n",
    "for companies_found in range(len(published_date_dict.keys())):\n",
    "    \n",
    "    ticker = list(published_date_dict.keys())[companies_found]\n",
    "    \n",
    "    comp_curr_ratio_dict = {}\n",
    "    comp_per_change_dict = {}\n",
    "    comp_bvps_dict = {}\n",
    "    comp_eps_dict = {}\n",
    "    comp_week_change_dict = {}\n",
    "    comp_month_change_dict = {}\n",
    "    comp_stock_price_dict = {}\n",
    "    \n",
    "    for date in published_date_dict[ticker]: \n",
    "        \n",
    "        y = date [0:4]\n",
    "        m = date [5:7]\n",
    "        d = date [9:10]\n",
    "        \n",
    "        stock_date = f'{m}/{d}/{y}'\n",
    "        \n",
    "        stock_path = os.path.join('..','Stock_Data','API_Stock_Data',f'{ticker}', f'{ticker}_{y}.csv')\n",
    "        stock_data_df = pd.read_csv(stock_path)\n",
    "        \n",
    "        \n",
    "        def find_entry():\n",
    "            for r in c_assets_df.iloc[:, 2]:\n",
    "                #Need to use date format finder instead\n",
    "                cref_list.append(int(r[-10:-3]))\n",
    "        \n",
    "        #Get the saved 10-K     \n",
    "        file_path = os.path.join('..','Financials',f'{filing_type}s',f'{ticker}', f'{ticker}_{date}.csv')\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        #Find the Current Ratio\n",
    "        c_assets_df = df[df['0'].str.contains('us-gaap:assetscurrent')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        curr_assets = c_assets_df[c_assets_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        \n",
    "        c_liab_df = df[df['0'].str.contains('us-gaap:liabilitiescurrent')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        curr_liab = c_liab_df[c_liab_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        \n",
    "        curr_ratio = (curr_assets / curr_liab).round(2)\n",
    "        comp_curr_ratio_dict[date] = curr_ratio\n",
    "        \n",
    "        #Find Book-Value Per Share\n",
    "        share_equity_df = df[df['0'].str.contains('us-gaap:stockholdersequity')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        share_equity = share_equity_df[share_equity_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        \n",
    "        shares_out_df = df[df['0'].str.contains('us-gaap:commonstocksharesoutstanding')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        shares_out = shares_out_df[shares_out_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        \n",
    "        bvps = share_equity / shares_out\n",
    "        comp_bvps_dict[date] = bvps\n",
    "        \n",
    "        \n",
    "        #Find Earnings per Share\n",
    "        inc_df = df[df['0'].str.contains('us-gaap:comprehensiveincomenetoftax')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        inc = inc_df[inc_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        eps = inc / shares_out\n",
    "        comp_eps_dict[date] = eps.round(2)\n",
    "        \n",
    "        #Find the pertinent Stock Data\n",
    "        release_day_data = stock_data_df[stock_data_df['Time'] == date]\n",
    "        release_day_close = release_day_data['Last']\n",
    "        \n",
    "        release_day_index = int(release_day_data.index.values)\n",
    "        \n",
    "        prior_day_data = stock_data_df.iloc[release_day_index-1]\n",
    "        next_day_data = stock_data_df.iloc[release_day_index+1]\n",
    "        five_day_data = stock_data_df.iloc[release_day_index+4]\n",
    "        month_day_data = stock_data_df.iloc[release_day_index+19]\n",
    "        \n",
    "        prior_day_close = prior_day_data['Last']\n",
    "        next_day_close = next_day_data['Last']\n",
    "        five_day_close = five_day_data['Last']\n",
    "        month_day_close = month_day_data['Last']\n",
    "        \n",
    "        comp_stock_price_dict[date] = int(next_day_close)\n",
    "        \n",
    "        per_change = ((next_day_close / prior_day_close) - 1) * 100\n",
    "        comp_per_change_dict[date] = per_change.round(2)\n",
    "        \n",
    "        week_change = ((five_day_close / prior_day_close) - 1) * 100\n",
    "        comp_week_change_dict[date] = week_change.round(2)\n",
    "        \n",
    "        month_change = ((month_day_close / prior_day_close) -1) * 100\n",
    "        comp_month_change_dict[date] = month_change.round(2)\n",
    "        \n",
    "    curr_ratio_dict[ticker] = comp_curr_ratio_dict\n",
    "    per_change_dict[ticker] = comp_per_change_dict\n",
    "    bvps_dict[ticker] = comp_bvps_dict\n",
    "    eps_dict[ticker] = comp_eps_dict\n",
    "    week_change_dict[ticker] = comp_week_change_dict\n",
    "    month_change_dict[ticker] = comp_month_change_dict\n",
    "    stock_price_dict[ticker] = comp_stock_price_dict\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n",
      "20180630\n",
      "                        0             1         2\n",
      "29  us-gaap:assetscurrent  1.157610e+11  FI2018Q3\n",
      "                              0             1         2\n",
      "457  us-gaap:liabilitiescurrent  8.854800e+10  FI2018Q3\n",
      "20180331\n",
      "                        0             1         2\n",
      "37  us-gaap:assetscurrent  1.300530e+11  FI2018Q2\n",
      "                              0             1         2\n",
      "468  us-gaap:liabilitiescurrent  8.932000e+10  FI2018Q2\n",
      "20171230\n",
      "                        0             1         2\n",
      "28  us-gaap:assetscurrent  1.438100e+11  FI2018Q1\n",
      "                              0             1         2\n",
      "419  us-gaap:liabilitiescurrent  1.157880e+11  FI2018Q1\n",
      "20170701\n",
      "                        0             1         2\n",
      "35  us-gaap:assetscurrent  1.128750e+11  FI2017Q3\n",
      "                              0             1         2\n",
      "481  us-gaap:liabilitiescurrent  8.130200e+10  FI2017Q3\n",
      "20170401\n",
      "                        0             1         2\n",
      "34  us-gaap:assetscurrent  1.019900e+11  FI2017Q2\n",
      "                              0             1         2\n",
      "460  us-gaap:liabilitiescurrent  7.334200e+10  FI2017Q2\n",
      "20161231\n",
      "                        0             1         2\n",
      "26  us-gaap:assetscurrent  1.033320e+11  FI2017Q1\n",
      "                              0             1         2\n",
      "370  us-gaap:liabilitiescurrent  8.413000e+10  FI2017Q1\n",
      "MMM\n",
      "20180930\n",
      "                        0             1                2\n",
      "52  us-gaap:assetscurrent  1.441900e+10  As_Of_9_30_2018\n",
      "52  us-gaap:assetscurrent  1.441900e+10  As_Of_9_30_2018\n",
      "                              0             1                2\n",
      "409  us-gaap:liabilitiescurrent  7.336000e+09  As_Of_9_30_2018\n",
      "409  us-gaap:liabilitiescurrent  7.336000e+09  As_Of_9_30_2018\n",
      "20180630\n",
      "                        0             1                2\n",
      "49  us-gaap:assetscurrent  1.389000e+10  As_Of_6_30_2018\n",
      "49  us-gaap:assetscurrent  1.389000e+10  As_Of_6_30_2018\n",
      "                              0             1                2\n",
      "418  us-gaap:liabilitiescurrent  8.902000e+09  As_Of_6_30_2018\n",
      "418  us-gaap:liabilitiescurrent  8.902000e+09  As_Of_6_30_2018\n",
      "20180331\n",
      "                        0             1                2\n",
      "35  us-gaap:assetscurrent  1.481800e+10  As_Of_3_31_2018\n",
      "35  us-gaap:assetscurrent  1.481800e+10  As_Of_3_31_2018\n",
      "                              0             1                2\n",
      "315  us-gaap:liabilitiescurrent  8.959000e+09  As_Of_3_31_2018\n",
      "315  us-gaap:liabilitiescurrent  8.959000e+09  As_Of_3_31_2018\n",
      "20170930\n",
      "                        0             1                2\n",
      "51  us-gaap:assetscurrent  1.365600e+10  As_Of_9_30_2017\n",
      "51  us-gaap:assetscurrent  1.365600e+10  As_Of_9_30_2017\n",
      "                              0             1                2\n",
      "466  us-gaap:liabilitiescurrent  6.598000e+09  As_Of_9_30_2017\n",
      "466  us-gaap:liabilitiescurrent  6.598000e+09  As_Of_9_30_2017\n",
      "20170630\n",
      "                        0             1                2\n",
      "49  us-gaap:assetscurrent  1.264100e+10  As_Of_6_30_2017\n",
      "49  us-gaap:assetscurrent  1.264100e+10  As_Of_6_30_2017\n",
      "                              0             1                2\n",
      "459  us-gaap:liabilitiescurrent  5.697000e+09  As_Of_6_30_2017\n",
      "459  us-gaap:liabilitiescurrent  5.697000e+09  As_Of_6_30_2017\n",
      "20170331\n",
      "                        0             1                2\n",
      "35  us-gaap:assetscurrent  1.190100e+10  As_Of_3_31_2017\n",
      "35  us-gaap:assetscurrent  1.190100e+10  As_Of_3_31_2017\n",
      "                              0             1                2\n",
      "369  us-gaap:liabilitiescurrent  5.995000e+09  As_Of_3_31_2017\n",
      "369  us-gaap:liabilitiescurrent  5.995000e+09  As_Of_3_31_2017\n"
     ]
    }
   ],
   "source": [
    "def find_entry():\n",
    "    y = test_date [0:4]\n",
    "    m = test_date [4:6]\n",
    "    d = test_date [6:8]\n",
    "    year_check = int(y) + 1\n",
    "\n",
    "    date_formats = [f'{y}{m}{d}', f'{y}-{m}-{d}', f'{m.lstrip(\"0\")}_{d.lstrip(\"0\")}_{y}']\n",
    "\n",
    "    quarter_list = ['Q4', 'Q3', \"Q2\", \"Q1\"]\n",
    "    context_ref = c_assets_df['2']\n",
    "\n",
    "\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    if len(context_ref) == 1:\n",
    "        test_df = test_df.append(c_assets_df)\n",
    "    elif len(context_ref) == 0:\n",
    "        print('Error, There are no Entries for that')\n",
    "    else:\n",
    "        while year_check >= (int(y)-1):\n",
    "            year_check_df = c_assets_df[context_ref.str.contains(f'{year_check}')]\n",
    "\n",
    "            if len(year_check_df) == 1:\n",
    "                test_df = test_df.append(year_check_df)\n",
    "                break\n",
    "            else: \n",
    "                for item in date_formats:\n",
    "                    if len(c_assets_df[context_ref.str.contains(f'{item}')]) == 1:\n",
    "                        test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{item}')])\n",
    "\n",
    "                        break\n",
    "                else:\n",
    "                    for quarter in quarter_list:\n",
    "                        if len(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')]) == 1:\n",
    "                            test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')])\n",
    "\n",
    "                            break\n",
    "                        elif len(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')]) == 1:\n",
    "                            test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')])\n",
    "                            break\n",
    "            year_check = year_check - 1\n",
    "    print(test_df)\n",
    "\n",
    "    \n",
    "for companies_found in range(len(published_date_dict.keys())):\n",
    "    ticker = list(published_date_dict.keys())[companies_found]\n",
    "    \n",
    "    comp_curr_ratio_dict = {}\n",
    "    comp_per_change_dict = {}\n",
    "    comp_bvps_dict = {}\n",
    "    comp_eps_dict = {}\n",
    "    comp_week_change_dict = {}\n",
    "    comp_month_change_dict = {}\n",
    "    comp_stock_price_dict = {}\n",
    "    \n",
    "    print(ticker)\n",
    "    \n",
    "    for date_index in range(len(as_of_date_dict[ticker])):\n",
    "        \n",
    "        #Get the saved 10-K     \n",
    "        file_path = os.path.join('..','Financials',f'{filing_type}s',f'{ticker}', f'{ticker}_{published_date_dict[ticker][date_index]}.csv')\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        #Find the Current Ratio\n",
    "        test_date = as_of_date_dict[ticker][date_index]\n",
    "        print(test_date)\n",
    "        \n",
    "        c_assets_df = df[df['0'].str.contains('us-gaap:assetscurrent')]\n",
    "        find_entry()\n",
    "        \n",
    "        c_assets_df = df[df['0'].str.contains('us-gaap:liabilitiescurrent')]\n",
    "        find_entry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Financials\\10-Ks\\AAPL\\AAPL_2019-10-31.csv\n",
      "..\\Financials\\10-Ks\\AAPL\\AAPL_2018-11-05.csv\n",
      "{'AAPL': ['20190928', '20180929']}\n",
      "{'AAPL': ['2019-10-31', '2018-11-05']}\n"
     ]
    }
   ],
   "source": [
    "def fetch_document_links(cells):\n",
    "    doc_link = 'https://www.sec.gov' + cells[1].a['href']\n",
    "\n",
    "    # Obtain HTML for document page\n",
    "    doc_resp = requests.get(doc_link)\n",
    "    doc_str = doc_resp.text\n",
    "    # Find the XBRL link\n",
    "    xbrl_link = ''\n",
    "    soup_doc = BeautifulSoup(doc_str, 'html.parser')\n",
    "    table_tag_doc = soup_doc.find('table', class_='tableFile', summary='Data Files')\n",
    "    rows_doc = table_tag_doc.find_all('tr')\n",
    "    for row_doc in rows_doc:\n",
    "        cells_doc = row_doc.find_all('td')\n",
    "        if len(cells_doc) > 3:\n",
    "            if int(year) > 2018:\n",
    "                if 'XML' in cells_doc[3].text:\n",
    "                    return 'https://www.sec.gov' + cells_doc[2].a['href']\n",
    "            else:\n",
    "                if 'INS' in cells_doc[3].text:\n",
    "                    return 'https://www.sec.gov' + cells_doc[2].a['href']\n",
    "\n",
    "def fetch_financial_data(tag_list, as_of_dates, df_dict):\n",
    "    \n",
    "    row_num = 0\n",
    "    \n",
    "    for tag in tag_list:\n",
    "        if 'schemaref' in tag.name:\n",
    "            ignored_href_index = len(ticker) + 1\n",
    "            as_of_date = tag['xlink:href'][ignored_href_index:(ignored_href_index+8)]\n",
    "            as_of_dates.append(as_of_date)\n",
    "            \n",
    "        if tag.name.find('us-gaap:') != -1:\n",
    "            try: \n",
    "                if float(tag.text) > 0:\n",
    "                    i = [f'{tag.name}', tag.text, tag['contextref']]\n",
    "                    df_dict[f'{row_num}'] = i\n",
    "                    row_num = row_num + 1\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "#Unmodified Base Code found at https://www.codeproject.com/Articles/1227765/Parsing-XBRL-with-Python\n",
    "#I added the ability for the code to query through a list of companies for multiple years and multiple quarters\n",
    "#and save the statements \n",
    "\n",
    "published_date_dict = {}\n",
    "as_of_date_dict = {}\n",
    "\n",
    "for companies_found in range(len(key_dict.keys())):\n",
    "    \n",
    "    company_name = list(key_dict.keys())[companies_found]\n",
    "    ticker = key_dict.get(company_name)[0]\n",
    "    \n",
    "    cik = key_dict.get(company_name)[1]\n",
    "    dateb = f'{years[0]}-12-31'\n",
    "    \n",
    "    # Obtain HTML for search page\n",
    "    base_url = \"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type={}&dateb={}\"\n",
    "    edgar_resp = requests.get(base_url.format(cik, filing_type, dateb))\n",
    "    edgar_str = edgar_resp.text\n",
    "    \n",
    "    doc_links = []\n",
    "    published_dates = []\n",
    "    as_of_dates = []\n",
    "            \n",
    "    # Find the document link\n",
    "    soup = BeautifulSoup(edgar_str, 'html.parser')\n",
    "    table_tag = soup.find('table', class_='tableFile2')\n",
    "    rows = table_tag.find_all('tr')\n",
    "        \n",
    "    for year in years:\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) > 3:\n",
    "                if year in cells[3].text:\n",
    "                    published_date = cells[3].text\n",
    "                    published_dates.append(published_date)\n",
    "\n",
    "                    xbrl_link = fetch_document_links(cells)\n",
    "                    # Obtain XBRL text from document\n",
    "                    xbrl_resp = requests.get(xbrl_link)\n",
    "                    xbrl_str = xbrl_resp.text\n",
    "               \n",
    "                    # Find and print stockholder's equity\n",
    "                    soup = BeautifulSoup(xbrl_str, 'lxml')\n",
    "                    tag_list = soup.find_all()\n",
    "                    \n",
    "                    df_dict = {}\n",
    "                    \n",
    "                    fetch_financial_data(tag_list, as_of_dates, df_dict)\n",
    "                    df = pd.DataFrame.from_dict(df_dict, orient='index')\n",
    "                    \n",
    "                    folder_path = os.path.join('..','Financials',f'{filing_type}s',f'{ticker}')\n",
    "                    file_path = os.path.join('..','Financials',f'{filing_type}s',f'{ticker}', f'{ticker}_{published_date}.csv')\n",
    "\n",
    "                    try:\n",
    "                        os.mkdir(folder_path)\n",
    "                    except FileExistsError:\n",
    "                        pass\n",
    "                    df.to_csv(file_path, index = False)\n",
    "                    print(file_path)\n",
    "\n",
    "    published_date_dict[ticker] = published_dates\n",
    "    as_of_date_dict[ticker] = as_of_dates\n",
    "    \n",
    "print(as_of_date_dict)\n",
    "print(published_date_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
