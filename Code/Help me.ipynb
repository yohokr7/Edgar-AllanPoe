{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = ['Facebook', 'Nvidia', 'Merck']\n",
    "years = ['2019', '2018']\n",
    "\n",
    "filing_type = '10-k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_ratio_dict = {}\n",
    "per_change_dict = {}\n",
    "bvps_dict = {}\n",
    "eps_dict = {}\n",
    "week_change_dict = {}\n",
    "month_change_dict = {}\n",
    "stock_price_dict = {}\n",
    "\n",
    "for companies_found in range(len(published_date_dict.keys())):\n",
    "    \n",
    "    ticker = list(published_date_dict.keys())[companies_found]\n",
    "    \n",
    "    comp_curr_ratio_dict = {}\n",
    "    comp_per_change_dict = {}\n",
    "    comp_bvps_dict = {}\n",
    "    comp_eps_dict = {}\n",
    "    comp_week_change_dict = {}\n",
    "    comp_month_change_dict = {}\n",
    "    comp_stock_price_dict = {}\n",
    "    \n",
    "    for date in published_date_dict[ticker]: \n",
    "        \n",
    "        y = date [0:4]\n",
    "        m = date [5:7]\n",
    "        d = date [9:10]\n",
    "        \n",
    "        stock_date = f'{m}/{d}/{y}'\n",
    "        \n",
    "        stock_path = os.path.join('..','Stock_Data','API_Stock_Data',f'{ticker}', f'{ticker}_{y}.csv')\n",
    "        stock_data_df = pd.read_csv(stock_path)\n",
    "        \n",
    "        \n",
    "        def find_entry():\n",
    "            for r in c_assets_df.iloc[:, 2]:\n",
    "                #Need to use date format finder instead\n",
    "                cref_list.append(int(r[-10:-3]))\n",
    "        \n",
    "        #Get the saved 10-K     \n",
    "        file_path = os.path.join('..','Financials',f'{filing_type}s',f'{ticker}', f'{ticker}_{date}.csv')\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        #Find the Current Ratio\n",
    "        c_assets_df = df[df['0'].str.contains('us-gaap:assetscurrent')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        curr_assets = c_assets_df[c_assets_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        \n",
    "        c_liab_df = df[df['0'].str.contains('us-gaap:liabilitiescurrent')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        curr_liab = c_liab_df[c_liab_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        \n",
    "        curr_ratio = (curr_assets / curr_liab).round(2)\n",
    "        comp_curr_ratio_dict[date] = curr_ratio\n",
    "        \n",
    "        #Find Book-Value Per Share\n",
    "        share_equity_df = df[df['0'].str.contains('us-gaap:stockholdersequity')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        share_equity = share_equity_df[share_equity_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        \n",
    "        shares_out_df = df[df['0'].str.contains('us-gaap:commonstocksharesoutstanding')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        shares_out = shares_out_df[shares_out_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        \n",
    "        bvps = share_equity / shares_out\n",
    "        comp_bvps_dict[date] = bvps\n",
    "        \n",
    "        \n",
    "        #Find Earnings per Share\n",
    "        inc_df = df[df['0'].str.contains('us-gaap:comprehensiveincomenetoftax')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        inc = inc_df[inc_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        eps = inc / shares_out\n",
    "        comp_eps_dict[date] = eps.round(2)\n",
    "        \n",
    "        #Find the pertinent Stock Data\n",
    "        release_day_data = stock_data_df[stock_data_df['Time'] == date]\n",
    "        release_day_close = release_day_data['Last']\n",
    "        \n",
    "        release_day_index = int(release_day_data.index.values)\n",
    "        \n",
    "        prior_day_data = stock_data_df.iloc[release_day_index-1]\n",
    "        next_day_data = stock_data_df.iloc[release_day_index+1]\n",
    "        five_day_data = stock_data_df.iloc[release_day_index+4]\n",
    "        month_day_data = stock_data_df.iloc[release_day_index+19]\n",
    "        \n",
    "        prior_day_close = prior_day_data['Last']\n",
    "        next_day_close = next_day_data['Last']\n",
    "        five_day_close = five_day_data['Last']\n",
    "        month_day_close = month_day_data['Last']\n",
    "        \n",
    "        comp_stock_price_dict[date] = int(next_day_close)\n",
    "        \n",
    "        per_change = ((next_day_close / prior_day_close) - 1) * 100\n",
    "        comp_per_change_dict[date] = per_change.round(2)\n",
    "        \n",
    "        week_change = ((five_day_close / prior_day_close) - 1) * 100\n",
    "        comp_week_change_dict[date] = week_change.round(2)\n",
    "        \n",
    "        month_change = ((month_day_close / prior_day_close) -1) * 100\n",
    "        comp_month_change_dict[date] = month_change.round(2)\n",
    "        \n",
    "    curr_ratio_dict[ticker] = comp_curr_ratio_dict\n",
    "    per_change_dict[ticker] = comp_per_change_dict\n",
    "    bvps_dict[ticker] = comp_bvps_dict\n",
    "    eps_dict[ticker] = comp_eps_dict\n",
    "    week_change_dict[ticker] = comp_week_change_dict\n",
    "    month_change_dict[ticker] = comp_month_change_dict\n",
    "    stock_price_dict[ticker] = comp_stock_price_dict\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! We were able to find 3 of your queries in the S&P 500\n",
      "We found: ['Facebook, Inc.', 'Nvidia Corporation', 'Merck & Co.'] in the S&P 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error, There are no Entries for that MRK20171231us-gaap:liabilities\n",
      "{'FB': {'2019-01-31': {0: {'91': 'us-gaap:cashandcashequivalentsatcarryingvalue', '52': 'us-gaap:assetscurrent', '50': 'us-gaap:assets', '376': 'us-gaap:liabilitiescurrent', '372': 'us-gaap:liabilities', '600': 'us-gaap:stockholdersequity'}, 1: {'91': 10019000000, '52': '50480000000', '50': '97334000000', '376': '7017000000', '372': '13207000000', '600': 84127000000}}, '2018-02-01': {0: {'86': 'us-gaap:cashandcashequivalentsatcarryingvalue', '58': 'us-gaap:assetscurrent', '56': 'us-gaap:assets', '355': 'us-gaap:liabilitiescurrent', '351': 'us-gaap:liabilities', '584': 'us-gaap:stockholdersequity'}, 1: {'86': 8079000000, '58': '48563000000', '56': '84524000000', '355': '3760000000', '351': '10177000000', '584': 74347000000}}}, 'NVDA': {'2019-02-21': {0: {'131': 'us-gaap:cashandcashequivalentsatcarryingvalue', '54': 'us-gaap:assetscurrent', '52': 'us-gaap:assets', '453': 'us-gaap:liabilitiescurrent', '446': 'us-gaap:liabilities', '774': 'us-gaap:stockholdersequity'}, 1: {'131': '782000000', '54': '10557000000', '52': '13292000000', '453': '1329000000', '446': '3950000000', '774': 12565000000}}, '2018-02-28': {0: {'172': 'us-gaap:cashandcashequivalentsatcarryingvalue', '54': 'us-gaap:assetscurrent', '52': 'us-gaap:assets', '485': 'us-gaap:liabilitiescurrent', '478': 'us-gaap:liabilities', '791': 'us-gaap:stockholdersequity'}, 1: {'172': '4002000000', '54': '9255000000', '52': '11241000000', '485': '1153000000', '478': '3770000000', '791': 8787000000}}}, 'MRK': {'2019-02-27': {0: {'180': 'us-gaap:cashandcashequivalentsatcarryingvalue', '45': 'us-gaap:assetscurrent', '43': 'us-gaap:assets', '1064': 'us-gaap:liabilitiescurrent', '1059': 'us-gaap:liabilities', '1984': 'us-gaap:stockholdersequity'}, 1: {'180': 8000000000, '45': '25875000000', '43': '82637000000', '1064': '22206000000', '1059': 600000000, '1984': '26701000000'}}, '2018-02-27': {0: {'222': 'us-gaap:cashandcashequivalentsatcarryingvalue', '38': 'us-gaap:assetscurrent', '36': 'us-gaap:assets', '1057': 'us-gaap:liabilitiescurrent', '1945': 'us-gaap:stockholdersequity'}, 1: {'222': 6100000000, '38': '24766000000', '36': '87872000000', '1057': '18614000000', '1945': '34336000000'}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import bs4\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Defining Functions\n",
    "\n",
    "# Checking Companies\n",
    "def company_check(company_list):\n",
    "    key_path = os.path.join('..','Financials', 'Ticker_and_CIK', 'Key.csv')\n",
    "    key_df = pd.read_csv(key_path)\n",
    "    key_dict = {}\n",
    "\n",
    "    for query in range(len(company_list)):\n",
    "        try:\n",
    "            company_df = key_df[key_df['Company'].str.contains(company_list[query].title())]\n",
    "            key_dict[company_df.iloc[0, 1]] = [company_df.iloc[0, 0], company_df.iloc[0, 2]]\n",
    "        except IndexError:\n",
    "            print(f\"{company_list[query]} could not be found\")\n",
    "    if key_dict == {}:\n",
    "        print (\"Whoops, none of your companies were on the S&P 500. Please try again!\")\n",
    "    else:\n",
    "        print (f\"Success! We were able to find {len(key_dict.keys())} of your queries in the S&P 500\")\n",
    "        print (f\"We found: {list(key_dict.keys())} in the S&P 500\")\n",
    "        return key_dict\n",
    "\n",
    "    \n",
    "# Obtaining Financials from the SEC\n",
    "def fetch_document_links(cells, year):\n",
    "    doc_link = 'https://www.sec.gov' + cells[1].a['href']\n",
    "    # Obtain HTML for document page\n",
    "    doc_resp = requests.get(doc_link)\n",
    "    doc_str = doc_resp.text\n",
    "    # Find the XBRL link\n",
    "    soup_doc = BeautifulSoup(doc_str, 'html.parser')\n",
    "    table_tag_doc = soup_doc.find('table', class_='tableFile', summary='Data Files')\n",
    "    rows_doc = table_tag_doc.find_all('tr')\n",
    "    for row_doc in rows_doc:\n",
    "        cells_doc = row_doc.find_all('td')\n",
    "        if len(cells_doc) > 3:\n",
    "                if 'XML' in cells_doc[3].text:\n",
    "                    return 'https://www.sec.gov' + cells_doc[2].a['href']\n",
    "                elif 'INS' in cells_doc[3].text:\n",
    "                    return 'https://www.sec.gov' + cells_doc[2].a['href'] \n",
    "                \n",
    "def fetch_financial_data(ticker, tag_list, as_of_dates, financial_dict):\n",
    "    row_num = 0\n",
    "    for tag in tag_list:\n",
    "        if 'schemaref' in tag.name:\n",
    "            ignored_href_index = len(ticker) + 1\n",
    "            as_of_date = tag['xlink:href'][ignored_href_index:(ignored_href_index+8)]\n",
    "            as_of_dates.append(as_of_date)\n",
    "            \n",
    "        if tag.name.find('us-gaap:') != -1:\n",
    "            try: \n",
    "                if float(tag.text) > 0:\n",
    "                    i = [f'{tag.name}', tag.text, tag['contextref']]\n",
    "                    financial_dict[f'{row_num}'] = i\n",
    "                    row_num = row_num + 1\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "            \n",
    "# Unmodified Base Code found at https://www.codeproject.com/Articles/1227765/Parsing-XBRL-with-Python\n",
    "def financial_scraper(key_dict, filing_type, published_date_dict, as_of_date_dict, agg_financial_dict):\n",
    "    #Looping through Companies in List\n",
    "    for companies_found in range(len(key_dict.keys())):\n",
    "        # Obtaining Ticker Symbol\n",
    "        company_name = list(key_dict.keys())[companies_found]\n",
    "        ticker = key_dict.get(company_name)[0]\n",
    "\n",
    "        cik = key_dict.get(company_name)[1]\n",
    "        dateb = f'{years[0]}-12-31'\n",
    "\n",
    "        # Obtain HTML for search page\n",
    "        base_url = \"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type={}&dateb={}\"\n",
    "        edgar_resp = requests.get(base_url.format(cik, filing_type, dateb))\n",
    "        edgar_str = edgar_resp.text\n",
    "\n",
    "        doc_links = []\n",
    "        published_dates = []\n",
    "        as_of_dates = []\n",
    "\n",
    "        # Find the document link\n",
    "        soup = BeautifulSoup(edgar_str, 'html.parser')\n",
    "        table_tag = soup.find('table', class_='tableFile2')\n",
    "        rows = table_tag.find_all('tr')\n",
    "        \n",
    "        all_years_dict = {}\n",
    "        \n",
    "        for year in years:\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                if len(cells) > 3:\n",
    "                    if year in cells[3].text:\n",
    "                        published_date = cells[3].text\n",
    "                        published_dates.append(published_date)\n",
    "\n",
    "                        xbrl_link = fetch_document_links(cells, year)\n",
    "                        # Obtain XBRL text from document\n",
    "                        xbrl_resp = requests.get(xbrl_link)\n",
    "                        xbrl_str = xbrl_resp.text\n",
    "\n",
    "                        # Find and print stockholder's equity\n",
    "                        soup = BeautifulSoup(xbrl_str, 'lxml')\n",
    "                        tag_list = soup.find_all()\n",
    "\n",
    "                        financial_dict = {}\n",
    "\n",
    "                        fetch_financial_data(ticker, tag_list, as_of_dates, financial_dict)\n",
    "                 \n",
    "                        all_years_dict[f'{published_date}'] = financial_dict\n",
    "                    \n",
    "        published_date_dict[ticker] = published_dates\n",
    "        as_of_date_dict[ticker] = as_of_dates\n",
    "        agg_financial_dict[ticker] = all_years_dict\n",
    "        \n",
    "        \n",
    "        \n",
    "# Finding Entries already Saved as Variable\n",
    "def find_entries(as_of_date_dict, published_date_dict, agg_financial_dict, journal_entry_name_list):\n",
    "    all_financial_dict = {}\n",
    "    \n",
    "    for companies_found in range(len(published_date_dict.keys())):\n",
    "        ticker = list(published_date_dict.keys())[companies_found]\n",
    "\n",
    "        comp_curr_ratio_dict = {}\n",
    "        comp_per_change_dict = {}\n",
    "        comp_bvps_dict = {}\n",
    "        comp_eps_dict = {}\n",
    "        comp_week_change_dict = {}\n",
    "        comp_month_change_dict = {}\n",
    "        comp_stock_price_dict = {}\n",
    "        \n",
    "        comp_financials_dict = {}\n",
    "\n",
    "        for date_index in range(len(as_of_date_dict[ticker])):\n",
    "            df = pd.DataFrame.from_dict(agg_financial_dict[ticker][(published_date_dict[ticker][date_index])], orient = 'index')\n",
    "            \n",
    "            date_index_financials_df = pd.DataFrame()\n",
    "            \n",
    "            for entry in journal_entry_name_list:\n",
    "                c_assets_df = df[df[0] == entry]\n",
    "                example = find_entry(as_of_date_dict, ticker, date_index, c_assets_df, entry)\n",
    "                date_index_financials_df = date_index_financials_df.append(example)    \n",
    "           \n",
    "            comp_financials_dict[published_date_dict[ticker][date_index]] = date_index_financials_df.iloc[:, 0:2].to_dict()\n",
    "        all_financial_dict[ticker] = comp_financials_dict\n",
    "    return all_financial_dict\n",
    "            \n",
    "def find_entry(as_of_date_dict, ticker, date_index, c_assets_df, entry):\n",
    "    \n",
    "    test_date = as_of_date_dict[ticker][date_index]\n",
    "    y = test_date [0:4]\n",
    "    m = test_date [4:6]\n",
    "    d = test_date [6:8]\n",
    "    \n",
    "    year_check = int(y) + 1\n",
    "    \n",
    "    quarter_list = ['Q4', 'Q3', \"Q2\", \"Q1\"]\n",
    "    context_ref = c_assets_df[2]\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    if len(context_ref) == 1:\n",
    "        # Only one entry\n",
    "        test_df = test_df.append(c_assets_df)\n",
    "        #print('Only 1 entry')\n",
    "    elif len(context_ref) == 0:\n",
    "        print(f'Error, There are no Entries for that {ticker}{test_date}{entry}')\n",
    "        \n",
    "    else:\n",
    "        while year_check >= (int(y)-1):\n",
    "            year_check_df = c_assets_df[context_ref.str.contains(f'{year_check}')]\n",
    "            \n",
    "            if len(year_check_df) == 1:\n",
    "                # Only 1 entry for the year\n",
    "                test_df = test_df.append(year_check_df)\n",
    "                #print('Only 1 entry of that year')\n",
    "                break\n",
    "            else: \n",
    "                date_formats = [f'{year_check}{m}{d}', f'{year_check}-{m}-{d}', f'{m.lstrip(\"0\")}_{d.lstrip(\"0\")}_{year_check}']\n",
    "\n",
    "                for item in date_formats:\n",
    "                    # Check through yyyymmdd, yyyy-mm-dd, and mm_dd_yyyy\n",
    "                    if len(c_assets_df[context_ref.str.contains(f'{item}')]) == 1:\n",
    "                        # Only 1 entry\n",
    "                        test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{item}')])\n",
    "                        #print(f'Context Ref uses {item} format')\n",
    "                        break\n",
    "                    elif len(c_assets_df[context_ref.str.contains(f'{item}')]) > 1:\n",
    "                        # Multiple Entries (usually in case of stockholder equity)\n",
    "                        stock_holder_df = c_assets_df[context_ref.str.contains(f'{item}')]\n",
    "                        stock_holder_df[1] = stock_holder_df[1].map(int)\n",
    "                        # Take Max Value given\n",
    "                        test_df = stock_holder_df[stock_holder_df[1] == stock_holder_df[1].max()].iloc[0]\n",
    "                        break\n",
    "                else:\n",
    "                    for quarter in quarter_list:\n",
    "                        # Check through q#yyyy\n",
    "                        if len(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')]) > 0:\n",
    "                            if len(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')]) == 1:\n",
    "                                test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')])\n",
    "                                #print(f'Context Ref uses {quarter}{year_check} format')\n",
    "                                break\n",
    "                            elif len(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')]) > 1:\n",
    "                                # Multiple Entries (usually in case of stockholder equity)\n",
    "                                stock_holder_df = c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')]\n",
    "                                stock_holder_df[1] = stock_holder_df[1].map(int)\n",
    "                                test_df = stock_holder_df[stock_holder_df[1] == stock_holder_df[1].max()].iloc[0]\n",
    "                                break\n",
    "                        elif len(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')]) > 0:\n",
    "                            if len(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')]) == 1:\n",
    "                                test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')])\n",
    "                                #print(f'Context Ref uses {year_check}{quarter} format')\n",
    "                                break\n",
    "                            elif len(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')]) > 1:\n",
    "                                # Multiple Entries (usually in case of stockholder equity)\n",
    "                                stock_holder_df = c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')]\n",
    "                                stock_holder_df[1] = stock_holder_df[1].map(int)\n",
    "                                test_df = stock_holder_df[stock_holder_df[1] == stock_holder_df[1].max()].iloc[0]\n",
    "                                break\n",
    "                if len(test_df) == 0:\n",
    "                    year_check = year_check - 1\n",
    "                else:\n",
    "                    year_check = int(y) - 2\n",
    "    return test_df\n",
    "\n",
    "            \n",
    "# Defining Date Dictionaries\n",
    "published_date_dict = {}\n",
    "as_of_date_dict = {}\n",
    "agg_financial_dict = {}\n",
    "\n",
    "journal_entry_name_list = ['us-gaap:cashandcashequivalentsatcarryingvalue', 'us-gaap:assetscurrent', 'us-gaap:assets',\\\n",
    "                                       'us-gaap:liabilitiescurrent', 'us-gaap:liabilities', 'us-gaap:stockholdersequity', \\\n",
    "                                       'us-gaap:cashandcashequivalentsatcarryingvalue']\n",
    "\n",
    "# Running Functions\n",
    "key_dict = company_check(company_list)\n",
    "financial_scraper(key_dict, filing_type, published_date_dict, as_of_date_dict, agg_financial_dict)\n",
    "html_table_dict = find_entries(as_of_date_dict, published_date_dict, agg_financial_dict, journal_entry_name_list)\n",
    "print(html_table_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\Stock_Data\\\\API_Stock_Data\\\\FB\\\\FB_2019.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-510ecfc7a160>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mstock_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Stock_Data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'API_Stock_Data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34mf'{ticker}'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{ticker}_{y}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mstock_data_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\Stock_Data\\\\API_Stock_Data\\\\FB\\\\FB_2019.csv'"
     ]
    }
   ],
   "source": [
    "curr_ratio_dict = {}\n",
    "per_change_dict = {}\n",
    "bvps_dict = {}\n",
    "eps_dict = {}\n",
    "week_change_dict = {}\n",
    "month_change_dict = {}\n",
    "stock_price_dict = {}\n",
    "\n",
    "for companies_found in range(len(published_date_dict.keys())):\n",
    "    \n",
    "    ticker = list(published_date_dict.keys())[companies_found]\n",
    "    \n",
    "    comp_curr_ratio_dict = {}\n",
    "    comp_per_change_dict = {}\n",
    "    comp_bvps_dict = {}\n",
    "    comp_eps_dict = {}\n",
    "    comp_week_change_dict = {}\n",
    "    comp_month_change_dict = {}\n",
    "    comp_stock_price_dict = {}\n",
    "    \n",
    "    for date in published_date_dict[ticker]: \n",
    "        \n",
    "        y = date [0:4]\n",
    "        m = date [5:7]\n",
    "        d = date [9:10]\n",
    "        \n",
    "        stock_date = f'{m}/{d}/{y}'\n",
    "        \n",
    "        stock_path = os.path.join('..','Stock_Data','API_Stock_Data',f'{ticker}', f'{ticker}_{y}.csv')\n",
    "        stock_data_df = pd.read_csv(stock_path)\n",
    "        \n",
    "        \n",
    "        def find_entry():\n",
    "            for r in c_assets_df.iloc[:, 2]:\n",
    "                #Need to use date format finder instead\n",
    "                cref_list.append(int(r[-10:-3]))\n",
    "        \n",
    "        #Get the saved 10-K     \n",
    "        file_path = os.path.join('..','Financials',f'{filing_type}s',f'{ticker}', f'{ticker}_{date}.csv')\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        #Find the Current Ratio\n",
    "        c_assets_df = df[df['0'].str.contains('us-gaap:assetscurrent')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        curr_assets = c_assets_df[c_assets_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        \n",
    "        c_liab_df = df[df['0'].str.contains('us-gaap:liabilitiescurrent')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        curr_liab = c_liab_df[c_liab_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        \n",
    "        curr_ratio = (curr_assets / curr_liab).round(2)\n",
    "        comp_curr_ratio_dict[date] = curr_ratio\n",
    "        \n",
    "        #Find Book-Value Per Share\n",
    "        share_equity_df = df[df['0'].str.contains('us-gaap:stockholdersequity')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        share_equity = share_equity_df[share_equity_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        \n",
    "        shares_out_df = df[df['0'].str.contains('us-gaap:commonstocksharesoutstanding')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        shares_out = shares_out_df[shares_out_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        \n",
    "        bvps = share_equity / shares_out\n",
    "        comp_bvps_dict[date] = bvps\n",
    "        \n",
    "        \n",
    "        #Find Earnings per Share\n",
    "        inc_df = df[df['0'].str.contains('us-gaap:comprehensiveincomenetoftax')]\n",
    "        cref_list = []\n",
    "        find_entry()\n",
    "        inc = inc_df[inc_df['2'].str.contains(str(max(cref_list)))].iloc[0,1]\n",
    "        eps = inc / shares_out\n",
    "        comp_eps_dict[date] = eps.round(2)\n",
    "        \n",
    "        #Find the pertinent Stock Data\n",
    "        release_day_data = stock_data_df[stock_data_df['Time'] == date]\n",
    "        release_day_close = release_day_data['Last']\n",
    "        \n",
    "        release_day_index = int(release_day_data.index.values)\n",
    "        print(release_day_index)\n",
    "        \n",
    "        prior_day_data = stock_data_df.iloc[release_day_index-1]\n",
    "        next_day_data = stock_data_df.iloc[release_day_index+1]\n",
    "        five_day_data = stock_data_df.iloc[release_day_index+4]\n",
    "        month_day_data = stock_data_df.iloc[release_day_index+19]\n",
    "        \n",
    "        prior_day_close = prior_day_data['Last']\n",
    "        next_day_close = next_day_data['Last']\n",
    "        five_day_close = five_day_data['Last']\n",
    "        month_day_close = month_day_data['Last']\n",
    "        \n",
    "        comp_stock_price_dict[date] = int(next_day_close)\n",
    "        \n",
    "        per_change = ((next_day_close / prior_day_close) - 1) * 100\n",
    "        comp_per_change_dict[date] = per_change.round(2)\n",
    "        \n",
    "        week_change = ((five_day_close / prior_day_close) - 1) * 100\n",
    "        comp_week_change_dict[date] = week_change.round(2)\n",
    "        \n",
    "        month_change = ((month_day_close / prior_day_close) -1) * 100\n",
    "        comp_month_change_dict[date] = month_change.round(2)\n",
    "        \n",
    "    curr_ratio_dict[ticker] = comp_curr_ratio_dict\n",
    "    per_change_dict[ticker] = comp_per_change_dict\n",
    "    bvps_dict[ticker] = comp_bvps_dict\n",
    "    eps_dict[ticker] = comp_eps_dict\n",
    "    week_change_dict[ticker] = comp_week_change_dict\n",
    "    month_change_dict[ticker] = comp_month_change_dict\n",
    "    stock_price_dict[ticker] = comp_stock_price_dict\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
