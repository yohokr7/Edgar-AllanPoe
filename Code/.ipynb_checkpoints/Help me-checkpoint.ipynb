{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import bs4\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = ['Apple']\n",
    "years = ['2017']\n",
    "filing_type = '10-Q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! We were able to find 1 of your queries in the S&P 500\n",
      "We found: ['Apple Inc.'] in the S&P 500\n",
      "{'Apple Inc.': ['AAPL', 320193]}\n"
     ]
    }
   ],
   "source": [
    "key_path = os.path.join('..','Financials', 'Ticker_and_CIK', 'Key.csv')\n",
    "\n",
    "key_df = pd.read_csv(key_path)\n",
    "\n",
    "key_dict = {}\n",
    "\n",
    "for query in range(len(company_list)):\n",
    "    try:\n",
    "        company_df = key_df[key_df['Company'].str.contains(company_list[query].title())]\n",
    "        key_dict[company_df.iloc[0, 1]] = [company_df.iloc[0, 0], company_df.iloc[0, 2]]\n",
    "    except IndexError:\n",
    "        print(f\"{company_list[query]} could not be found\")\n",
    "\n",
    "if key_dict == {}:\n",
    "    print (\"Whoops, none of your companies were on the S&P 500. Please try again!\")\n",
    "else:\n",
    "    print (f\"Success! We were able to find {len(key_dict.keys())} of your queries in the S&P 500\")\n",
    "    print (f\"We found: {list(key_dict.keys())} in the S&P 500\")\n",
    "    print (key_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/320193/000032019317000009/aapl-20170701.xml\n",
      "https://www.sec.gov/Archives/edgar/data/320193/000162828017004790/aapl-20170401.xml\n",
      "https://www.sec.gov/Archives/edgar/data/320193/000162828017000717/aapl-20161231.xml\n",
      "{'AAPL': ['20170701', '20170401', '20161231']}\n",
      "{'AAPL': ['2017-08-02', '2017-05-03', '2017-02-01']}\n"
     ]
    }
   ],
   "source": [
    "#Unmodified Base Code found at https://www.codeproject.com/Articles/1227765/Parsing-XBRL-with-Python\n",
    "#I added the ability for the code to query through a list of companies for multiple years and multiple quarters\n",
    "#and save the statements \n",
    "\n",
    "published_date_dict = {}\n",
    "as_of_date_dict = {}\n",
    "\n",
    "for companies_found in range(len(key_dict.keys())):\n",
    "    \n",
    "    company_name = list(key_dict.keys())[companies_found]\n",
    "    ticker = key_dict.get(company_name)[0]\n",
    "    \n",
    "    cik = key_dict.get(company_name)[1]\n",
    "    dateb = f'{years[0]}-12-31'\n",
    "    \n",
    "    # Obtain HTML for search page\n",
    "    base_url = \"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type={}&dateb={}\"\n",
    "    edgar_resp = requests.get(base_url.format(cik, filing_type, dateb))\n",
    "    edgar_str = edgar_resp.text\n",
    "    \n",
    "    doc_links = []\n",
    "    published_dates = []\n",
    "    as_of_dates = []\n",
    "            \n",
    "    # Find the document link\n",
    "    soup = BeautifulSoup(edgar_str, 'html.parser')\n",
    "    table_tag = soup.find('table', class_='tableFile2')\n",
    "    rows = table_tag.find_all('tr')\n",
    "        \n",
    "    for year in years:\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) > 3:\n",
    "                if year in cells[3].text:\n",
    "                    doc_link = 'https://www.sec.gov' + cells[1].a['href']\n",
    "                    published_date = cells[3].text\n",
    "                    published_dates.append(published_date)\n",
    "                    \n",
    "                    # Obtain HTML for document page\n",
    "                    doc_resp = requests.get(doc_link)\n",
    "                    doc_str = doc_resp.text\n",
    "                    # Find the XBRL link\n",
    "                    xbrl_link = ''\n",
    "                    soup_doc = BeautifulSoup(doc_str, 'html.parser')\n",
    "                    table_tag_doc = soup_doc.find('table', class_='tableFile', summary='Data Files')\n",
    "                    rows_doc = table_tag_doc.find_all('tr')\n",
    "                    for row_doc in rows_doc:\n",
    "                        cells_doc = row_doc.find_all('td')\n",
    "                        if len(cells_doc) > 3:\n",
    "                            if 'INS' in cells_doc[3].text:\n",
    "                                xbrl_link = 'https://www.sec.gov' + cells_doc[2].a['href']\n",
    "                                print(xbrl_link)\n",
    "                    # Obtain XBRL text from document\n",
    "                    xbrl_resp = requests.get(xbrl_link)\n",
    "                    xbrl_str = xbrl_resp.text\n",
    "               \n",
    "                    # Find and print stockholder's equity\n",
    "                    soup = BeautifulSoup(xbrl_str, 'lxml')\n",
    "                    tag_list = soup.find_all()\n",
    "                    \n",
    "                    df = pd.DataFrame()\n",
    "                    \n",
    "                    for tag in tag_list:\n",
    "                        if 'schemaref' in tag.name:\n",
    "                            ignored_href_index = len(ticker) + 1\n",
    "                            as_of_date = tag['xlink:href'][ignored_href_index:(ignored_href_index+8)]\n",
    "                            as_of_dates.append(as_of_date)\n",
    "                            \n",
    "                         #Modified from the original; The original searched through to find specific line items\n",
    "                        #Modified to search through every 10-Q per given year, and extract any financial line item into its own 10-Q\n",
    "\n",
    "                        if tag.name.find('us-gaap:') != -1:\n",
    "                            try: \n",
    "                                if float(tag.text) > 0:\n",
    "                                    i = [f'{tag.name}', tag.text, tag['contextref']]\n",
    "                                    i_series = pd.Series(i)\n",
    "                                    df = df.append(i_series, ignore_index = True)\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "\n",
    "                    folder_path = os.path.join('..','Financials',f'{filing_type}s',f'{ticker}')\n",
    "                    file_path = os.path.join('..','Financials',f'{filing_type}s',f'{ticker}', f'{ticker}_{published_date}.csv')\n",
    "\n",
    "                    try:\n",
    "                        os.mkdir(folder_path)\n",
    "                    except FileExistsError:\n",
    "                        pass\n",
    "                    df.to_csv(file_path, index = False)\n",
    "\n",
    "    published_date_dict[ticker] = published_dates\n",
    "    as_of_date_dict[ticker] = as_of_dates\n",
    "    \n",
    "print(as_of_date_dict)\n",
    "print(published_date_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0             1         2\n",
      "25  us-gaap:assetscurrent  1.068690e+11  FI2016Q4\n",
      "26  us-gaap:assetscurrent  1.033320e+11  FI2017Q1\n",
      "Series([], Name: 2, dtype: object)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = \"2017-02-01\"\n",
    "year = 2017\n",
    "\n",
    "#Get the saved 10-K     \n",
    "file_path = os.path.join('..','Financials',f'{filing_type}s',f'{ticker}', f'{ticker}_{date}.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "#Find the Current Ratio\n",
    "c_assets_df = df[df['0'].str.contains('us-gaap:assetscurrent')]\n",
    "print(c_assets_df)\n",
    "\n",
    "print(c_assets_df['2'][c_assets_df['2']==2017])\n",
    "\n",
    "reduced_df = c_assets_df[c_assets_df['2'].str.contains(f'{year}')]\n",
    "\n",
    "#if len(reduced_df ==)\n",
    "len(reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0             1         2\n",
      "26  us-gaap:assetscurrent  1.033320e+11  FI2017Q1\n"
     ]
    }
   ],
   "source": [
    "test_date = '20170201'\n",
    "\n",
    "y = test_date [0:4]\n",
    "m = test_date [4:6]\n",
    "d = test_date [6:8]\n",
    "year_check = int(y) + 1\n",
    "\n",
    "date_formats = [f'{y}{m}{d}', f'{y}-{m}-{d}', f'{m.lstrip(\"0\")}_{d.lstrip(\"0\")}_{y}']\n",
    "\n",
    "\n",
    "quarter_list = ['Q4', 'Q3', \"Q2\", \"Q1\"]\n",
    "\n",
    "context_ref = c_assets_df['2']\n",
    "\n",
    "\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "if len(context_ref) == 1:\n",
    "    test_df = test_df.append(c_assets_df)\n",
    "elif len(context_ref) == 0:\n",
    "    print('Error, There are no Entries for that')\n",
    "else:\n",
    "    while year_check >= (int(y)-1):\n",
    "        year_check_df = c_assets_df[context_ref.str.contains(f'{year_check}')]\n",
    "        \n",
    "        if len(year_check_df) == 1:\n",
    "            test_df = test_df.append(year_check_df)\n",
    "            break\n",
    "        else: \n",
    "            for item in date_formats:\n",
    "                if len(c_assets_df[context_ref.str.contains(f'{item}')]) == 1:\n",
    "                    test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{item}')])\n",
    "                    \n",
    "                    break\n",
    "            else:\n",
    "                for quarter in quarter_list:\n",
    "                    if len(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')]) == 1:\n",
    "                        test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')])\n",
    "                        \n",
    "                        break\n",
    "                    elif len(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')]) == 1:\n",
    "                        test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')])\n",
    "                        break\n",
    "        year_check = year_check - 1\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
